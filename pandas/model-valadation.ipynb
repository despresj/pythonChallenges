{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Unnamed: 0', 'score', 'rank', 'ethnicity', 'gender', 'language', 'age',\n       'cls_perc_eval', 'cls_did_eval', 'cls_students', 'cls_level',\n       'cls_profs', 'cls_credits', 'bty_f1lower', 'bty_f1upper', 'bty_f2upper',\n       'bty_m1lower', 'bty_m1upper', 'bty_m2upper', 'bty_avg',\n       'tenure_eligible'],\n      dtype='object')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(here(\"pandas/data/evals-mod-adj.csv\"))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['bty_avg']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(df['score'], X)\n",
    "results_simple = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>          <td>score</td>      <th>  R-squared:         </th> <td>   0.035</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.033</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.73</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 22 Mar 2021</td> <th>  Prob (F-statistic):</th> <td>5.08e-05</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>08:36:35</td>     <th>  Log-Likelihood:    </th> <td> -366.22</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>   463</td>      <th>  AIC:               </th> <td>   736.4</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>   461</td>      <th>  BIC:               </th> <td>   744.7</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>   <td>    3.8803</td> <td>    0.076</td> <td>   50.961</td> <td> 0.000</td> <td>    3.731</td> <td>    4.030</td>\n</tr>\n<tr>\n  <th>bty_avg</th> <td>    0.0666</td> <td>    0.016</td> <td>    4.090</td> <td> 0.000</td> <td>    0.035</td> <td>    0.099</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>33.007</td> <th>  Durbin-Watson:     </th> <td>   1.267</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  38.796</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.709</td> <th>  Prob(JB):          </th> <td>3.76e-09</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 3.006</td> <th>  Cond. No.          </th> <td>    14.9</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  score   R-squared:                       0.035\nModel:                            OLS   Adj. R-squared:                  0.033\nMethod:                 Least Squares   F-statistic:                     16.73\nDate:                Mon, 22 Mar 2021   Prob (F-statistic):           5.08e-05\nTime:                        08:36:35   Log-Likelihood:                -366.22\nNo. Observations:                 463   AIC:                             736.4\nDf Residuals:                     461   BIC:                             744.7\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.8803      0.076     50.961      0.000       3.731       4.030\nbty_avg        0.0666      0.016      4.090      0.000       0.035       0.099\n==============================================================================\nOmnibus:                       33.007   Durbin-Watson:                   1.267\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               38.796\nSkew:                          -0.709   Prob(JB):                     3.76e-09\nKurtosis:                       3.006   Cond. No.                         14.9\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coef.</th>\n      <th>Std.Err.</th>\n      <th>t</th>\n      <th>P&gt;|t|</th>\n      <th>[0.025</th>\n      <th>0.975]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>const</th>\n      <td>3.880333</td>\n      <td>0.076143</td>\n      <td>50.960964</td>\n      <td>1.564021e-191</td>\n      <td>3.730702</td>\n      <td>4.029963</td>\n    </tr>\n    <tr>\n      <th>bty_avg</th>\n      <td>0.066637</td>\n      <td>0.016291</td>\n      <td>4.090440</td>\n      <td>5.081508e-05</td>\n      <td>0.034623</td>\n      <td>0.098651</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            Coef.  Std.Err.          t          P>|t|    [0.025    0.975]\nconst    3.880333  0.076143  50.960964  1.564021e-191  3.730702  4.029963\nbty_avg  0.066637  0.016291   4.090440   5.081508e-05  0.034623  0.098651"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRresult = (results_simple.summary2().tables[1])\n",
    "LRresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.03292999149286491"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_simple.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['female', 'male']]= pd.get_dummies(df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['bty_avg', 'male']]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(df['score'], X)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "const      3.747335\nbty_avg    0.074155\nmale       0.172389\nName: Coef., dtype: float64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table = results.summary2().tables[1]\n",
    "result_table['Coef.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "const      44.265879\nbty_avg     4.562841\nmale        3.432607\nName: t, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table['t']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holding all else constant we can see that males get a significantly higher score on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.03292999149286491"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_simple.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.055032774550898944"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.rsquared_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that adding gender as a predictor is helpfun in predicting score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coef.</th>\n      <th>Std.Err.</th>\n      <th>t</th>\n      <th>P&gt;|t|</th>\n      <th>[0.025</th>\n      <th>0.975]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>3.981539</td>\n      <td>0.090780</td>\n      <td>43.859135</td>\n      <td>2.943219e-166</td>\n      <td>3.803143</td>\n      <td>4.159936</td>\n    </tr>\n    <tr>\n      <th>rank[T.tenure track]</th>\n      <td>-0.160697</td>\n      <td>0.073951</td>\n      <td>-2.173012</td>\n      <td>3.029015e-02</td>\n      <td>-0.306021</td>\n      <td>-0.015372</td>\n    </tr>\n    <tr>\n      <th>rank[T.tenured]</th>\n      <td>-0.126219</td>\n      <td>0.062662</td>\n      <td>-2.014299</td>\n      <td>4.456101e-02</td>\n      <td>-0.249359</td>\n      <td>-0.003080</td>\n    </tr>\n    <tr>\n      <th>bty_avg</th>\n      <td>0.067825</td>\n      <td>0.016550</td>\n      <td>4.098296</td>\n      <td>4.921486e-05</td>\n      <td>0.035303</td>\n      <td>0.100347</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                         Coef.  Std.Err.          t          P>|t|    [0.025  \\\nIntercept             3.981539  0.090780  43.859135  2.943219e-166  3.803143   \nrank[T.tenure track] -0.160697  0.073951  -2.173012   3.029015e-02 -0.306021   \nrank[T.tenured]      -0.126219  0.062662  -2.014299   4.456101e-02 -0.249359   \nbty_avg               0.067825  0.016550   4.098296   4.921486e-05  0.035303   \n\n                        0.975]  \nIntercept             4.159936  \nrank[T.tenure track] -0.015372  \nrank[T.tenured]      -0.003080  \nbty_avg               0.100347  "
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = smf.ols(formula='score ~ bty_avg + rank', data=df)\n",
    "res = mod.fit()\n",
    "res.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rank, ethnicity, gender, language, age, cls_perc_eval, cls_did_eval, cls_students, cls_level, cls_profs, cls_credits, bty_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwds = df[[ 'score', 'rank',\n",
    " 'ethnicity',\n",
    " 'gender',\n",
    " 'language',\n",
    " 'age',\n",
    " 'cls_perc_eval',\n",
    " 'cls_did_eval',\n",
    " 'cls_students',\n",
    " 'cls_level',\n",
    " 'cls_profs',\n",
    " 'cls_credits',\n",
    " 'bty_avg']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}